%!TEX root = main.tex
\section{Motivation}
\label{sec:motivation}
The assessment of software quality is one of the most multifaceted (\eg structural quality, product quality, process quality, etc.) and subjective aspects of software engineering (since in many cases it is substantially based on expert judgement). Such assessments can be performed at almost all phases of software development (from project inception to maintenance) and at different levels of granularity (from source code to architecture). However, human judgement is: (a) inherently biased by implicit, subjective criteria applied in the evaluation process, and (b) its economical effectiveness is limited compared to automated or semi-automated approaches. To this end, researchers are still looking for new, more effective methods of assessing various qualitative characteristics of software systems and the related processes.
In recent years we have been observing a rising interest in adopting various approaches to exploiting machine learning (ML) and automated decision- making processes in several areas of software engineering. These models and algorithms help to reduce effort and risk related to human judgment in favor of automated systems, which are able to make informed decisions based on available data and evaluated with objective criteria. Thus, the adoption of machine learning techniques seems to be one of the most promising ways to improve software quality evaluation.
Conversely, learning capabilities are increasingly often embedded within software, including in critical domains such as automotive and health. This calls for the application of quality assurance techniques to ensure the reliable engineering of ML-based software systems.
After the successful editions of the workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE), that have been held in Klagenfurt (Austria) on February 21$^{st}$, 2017, collocated with SANER 2017 in Campobasso (Italy) on March 23$^{rd}$ , 2018, collocated with SANER 2018, and in Tallin (Estonia) on August 27$^{th}$ 2019, collocated with ESEC/FSE 2019, we propose a novel edition of the workshop.






